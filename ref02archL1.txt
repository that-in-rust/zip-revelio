Before we start let's understand the @ref01prd.txt problem space

we need to have some good notes on zip file format before we start

Key ZIP Format Facts for Our Implementation:

1. Structure
- Directory (catalog) at end of file - enables quick file listing without reading whole archive
- Each file compressed separately - allows parallel decompression
- Uses 32-bit CRC for data integrity
- Minimum size: 22 bytes (empty ZIP)
- Max size: 4GB (standard) or 16EB (ZIP64)

2. Compression
- Multiple methods supported but DEFLATE most common
- Files can use different compression methods in same archive
- Files can be stored uncompressed
- Individual compression enables random access

3. Performance Considerations 
- Can read directory without processing whole file
- Parallel decompression possible since files independent
- SOZip extension enables fast random access
- No need to decompress entire archive to extract single file

4. Constraints (per PRD)
- ASCII filenames only
- Support Store/Deflate methods only
- Need parallel processing
- Must handle large files efficiently

5. Implementation Strategy
- Use end-first reading to get directory quickly
- Leverage parallel decompression with rayon
- Handle Store/Deflate with tokio async I/O
- Track stats like compression ratio per file


Append below this - Give me 3 variations of an MVP PRD which can help us solve @ref01prd.txt while also making sure we can show how good we are at parallel processing & async programming - use research from the web if needed - each PRD should be note more than 7 bullets



MVP Variation 1 - Streaming Focus:
- Stream ZIP directory from end using tokio async I/O (max 4GB standard ZIP)
- Process files in parallel chunks using rayon (ASCII filenames only)
- Use memory-mapped files for large archives (Store/Deflate only)
- Track progress with custom async progress bar
- Generate stats while streaming to avoid memory bloat
- Support graceful cancellation
- Output streaming JSON report
- Simple CLI: `cargo run -- input.zip output.txt`

MVP Variation 2 - Maximum Parallelism:
- Read entire directory upfront for optimal scheduling (4GB ZIP limit)
- Decompress multiple files simultaneously with rayon (ASCII names)
- Use thread pool for I/O operations (Store/Deflate methods)
- Maintain concurrent stats counters
- Dynamic thread count based on system load
- Buffer pool for memory reuse
- Real-time progress updates
- Simple CLI: `cargo run -- input.zip output.txt`

MVP Variation 3 - Memory Efficient:
- Read directory in chunks asynchronously (Standard ZIP < 4GB)
- Process fixed-size blocks in parallel (ASCII filenames)
- Use shared buffer pool to limit memory (Store/Deflate only)
- Aggregate stats with atomic counters
- Backpressure for large files
- Cancelable async operations
- Incremental report generation
- Simple CLI: `cargo run -- input.zip output.txt`


Which of the above 3 variations would be fastest?

Variation 2 (Maximum Parallelism) would likely be fastest because:

1. Reading directory upfront eliminates seeking overhead
2. Maximum parallel decompression with rayon
3. Dedicated thread pool for I/O operations
4. No streaming overhead or backpressure
5. Memory tradeoff for speed (uses more RAM)

However, it requires more memory and has a 4GB ZIP size limit. For very large files, Variation 1 (Streaming) may be faster due to better memory locality.

This is because:
1. Large files exceed CPU cache size when fully loaded
2. Streaming processes data in cache-friendly chunks
3. Memory pressure from full loads causes swapping
4. Sequential reads are faster than random access
5. Lower memory usage means more OS cache available


Comparing MVP Variations - Detailed Analysis:

1. MVP1 (Streaming) Tradeoffs:
- Pros:
  * Lower memory footprint
  * Better for huge files
  * More predictable resource usage
- Cons:
  * Higher I/O overhead
  * More complex error handling
  * Potentially slower for small files

2. MVP2 (Maximum Parallelism) Tradeoffs:
- Pros:
  * Fastest for small/medium files
  * Simpler implementation
  * Better CPU utilization
- Cons:
  * High memory usage
  * Resource contention risk
  * 4GB ZIP limit

3. MVP3 (Memory Efficient) Tradeoffs:
- Pros:
  * Balanced performance
  * Controlled resource usage
  * Good scalability
- Cons:
  * More complex coordination
  * Higher development effort
  * Potential bottlenecks

Key Risks of MVP2 (Maximum Parallelism):

1. Memory Explosion
- Reading entire directory upfront could exhaust RAM on large ZIPs
- Multiple parallel decompression streams multiply memory usage
- Buffer pools could fragment memory under heavy load

2. Resource Contention
- Too many threads can cause thrashing
- I/O bottlenecks when many threads hit disk simultaneously  
- Thread pool saturation under heavy load
- CPU cache thrashing from context switching

3. Error Handling Complexity
- Harder to maintain consistent state across threads
- Error in one thread could corrupt shared data
- Need careful coordination for cleanup on failures
- Race conditions in stats collection

4. System Impact
- High CPU/memory pressure affects other processes
- Disk I/O saturation slows system
- Potential thermal throttling on heavy loads
- Network impact if reading remote ZIPs

5. Edge Cases
- ZIP bomb attacks could amplify memory issues
- Corrupt files may crash worker threads
- Thread pool exhaustion on many small files
- Deadlocks from improper resource sharing

Recommended Mitigations:

1. Memory limits:
```rust
const MAX_PARALLEL_FILES: usize = 4;
let semaphore = Arc::new(Semaphore::new(MAX_PARALLEL_FILES));
```

2. Graceful degradation:
```rust
let thread_count = available_parallelism().unwrap().get().min(8);
```

3. Circuit breaker:
```rust
let breaker = Arc::new(AtomicBool::new(false));
if memory_pressure() > threshold {
    breaker.store(true, Ordering::SeqCst);
}
```

4. Resource monitoring:
```rust
let memory_usage = Arc::new(AtomicUsize::new(0));
memory_usage.fetch_add(size, Ordering::SeqCst);
```

5. Timeout protection:
```rust
let timeout = Duration::from_secs(30);
tokio::time::timeout(timeout, process_file(entry))?;
```

Final Recommendation:
Start with MVP2 but implement these safeguards:
```rust
// 1. Adaptive parallelism
let optimal_threads = std::cmp::min(
    num_cpus::get(),
    file_size / CHUNK_SIZE
);

// 2. Memory monitoring
const MAX_MEMORY: usize = 1024 * 1024 * 1024; // 1GB
let current_usage = Arc::new(AtomicUsize::new(0));

// 3. Backpressure mechanism
let (tx, rx) = tokio::sync::mpsc::channel(100);
if current_usage.load(Ordering::Relaxed) > MAX_MEMORY {
    rx.recv().await?; // Wait for space
}

// 4. Graceful degradation
if system_pressure() > threshold {
    // Fall back to streaming mode
    switch_to_streaming_mode().await?;
}

// 5. Circuit breaker pattern
let breaker = Arc::new(AtomicBool::new(false));
if error_count.load(Ordering::Relaxed) > MAX_ERRORS {
    breaker.store(true, Ordering::SeqCst);
}
```

This gives us maximum performance while maintaining safety nets.

