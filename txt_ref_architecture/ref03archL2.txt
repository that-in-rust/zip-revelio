# ZIP-Revelio: Detailed Architecture (L2) üîç

"Like a well-oiled assembly line, each component knows its job and communicates efficiently with others!"

## Core Data Structures

1. ZIP Entry
```rust
#[derive(Debug)]
pub struct ZipEntry {
    header: LocalFileHeader,
    data_descriptor: Option<DataDescriptor>,
    file_data: Vec<u8>,
}

#[derive(Debug)]
pub struct LocalFileHeader {
    version_needed: u16,
    flags: u16,
    compression_method: u16,
    last_mod_time: u16,
    last_mod_date: u16,
    crc32: u32,
    compressed_size: u64,
    uncompressed_size: u64,
    file_name: String,
    extra_field: Vec<u8>,
}

impl ZipEntry {
    async fn process(&self, buffer: &mut Buffer) -> Result<ProcessedEntry, ZipError> {
        self.validate()?;
        match self.header.compression_method {
            0 => { /* Store */ },
            8 => { /* Deflate */ },
            _ => Err(ZipError::UnsupportedMethod(..)),
        }
    }
}
```

2. Analysis Stats
```rust
struct Stats {
    // Size Information
    total_size: AtomicU64,
    compressed_size: AtomicU64,
    
    // File Counts
    file_count: AtomicUsize,
    
    // Timing
    start_time: Instant,
    duration: AtomicU64,
    
    // Categorization
    methods: DashMap<u16, usize>,    // Compression methods
    types: DashMap<String, usize>,   // File extensions
    
    // File List
    files: RwLock<BTreeSet<String>>, // Sorted file list
}

impl Stats {
    fn compression_ratio(&self) -> f64 {
        let total = self.total_size.load(Ordering::Relaxed);
        let compressed = self.compressed_size.load(Ordering::Relaxed);
        if total == 0 { 0.0 } else { compressed as f64 / total as f64 * 100.0 }
    }
}
```

## Component Details

1. Reader Module
```
                        ‚îå‚îÄ AsyncBufReader
                        ‚îÇ
ZIP File ‚îÄ‚îÄ‚Üí [mmap?] ‚îÄ‚îÄ‚îº‚îÄ Central Directory
                        ‚îÇ
                        ‚îî‚îÄ Entry Headers
```

```rust
// Key Functions
async fn read_central_directory() -> Vec<ZipEntry>
async fn read_entry_data(entry: &ZipEntry) -> Vec<u8>
async fn stream_entry(entry: &ZipEntry) -> impl Stream
```

2. Processor Module
```
                    ‚îå‚îÄ Store
Entry Data ‚îÄ‚îÄ‚Üí [Method?]
                    ‚îî‚îÄ Deflate
                         ‚îÇ
                    [Parallel Process]
                         ‚îÇ
                    [Update Stats]
```

```rust
// Processing Pipeline
fn process_entries(entries: Vec<ZipEntry>) {
    entries.par_iter()          // Parallel iterator
           .with_pool(pool)     // Custom thread pool
           .for_each(|entry| {  // Process each entry
               let buffer = get_buffer(entry.buffer_id);
               match entry.method {
                   0 => process_stored(entry, buffer),
                   8 => process_deflated(entry, buffer),
                   _ => skip(entry),
               }
           })
}
```

3. Reporter Module
```
Stats ‚îÄ‚îÄ‚Üí [Aggregate] ‚îÄ‚îÄ‚Üí [Format] ‚îÄ‚îÄ‚Üí Output
```

## Memory Management

1. Buffer Pool
```rust
pub enum Buffer {
    Small(Vec<u8>),     // <64KB
    Medium(Vec<u8>),    // <1MB
    Large(usize),       // Memory map ID
}

pub struct BufferPool {
    small_pool: ArrayQueue<Vec<u8>>,
    medium_pool: ArrayQueue<Vec<u8>>,
    large_maps: RwLock<HashMap<usize, MemoryMap>>,
    config: BufferConfig,
}

impl BufferPool {
    fn acquire(&self, size: usize) -> Result<Buffer, ZipError> {
        match size {
            s if s <= SMALL_SIZE => self.get_small_buffer(),
            s if s <= MEDIUM_SIZE => self.get_medium_buffer(),
            s => self.create_memory_map(s),
        }
    }
}
```

2. Memory Mapping
```rust
impl MemoryMap {
    fn new(size: usize) -> io::Result<Self> {
        let file = tempfile()?;
        file.set_len(size as u64)?;
        
        let map = unsafe {
            MmapOptions::new()
                .len(size)
                .map_mut(&file)?
        };
        
        Ok(Self { map })
    }
}
```

## Thread Pool Management

1. Worker Configuration
```rust
struct WorkerConfig {
    thread_count: usize,
    stack_size: usize,
    buffer_pool: Arc<BufferPool>,
    progress: Arc<Progress>,
}

impl WorkerConfig {
    fn optimal_threads(file_count: usize) -> usize {
        min(
            num_cpus::get(),
            max(1, file_count / 10)
        )
    }
}
```

2. Work Distribution
```rust
struct WorkDistributor {
    entries: Vec<Arc<ZipEntry>>,
    chunk_size: usize,
    current: AtomicUsize,
}

impl WorkDistributor {
    fn next_chunk(&self) -> Option<Vec<Arc<ZipEntry>>> {
        let start = self.current.fetch_add(
            self.chunk_size, 
            Ordering::AcqRel
        );
        if start >= self.entries.len() {
            None
        } else {
            Some(self.entries[start..].to_vec())
        }
    }
}
```

## Progress Tracking

1. Progress Bar
```rust
pub struct Progress {
    bar: ProgressBar,
    processed: AtomicU64,
    total: u64,
    speed: RwLock<f64>,
    last_update: AtomicU64,
}

impl Progress {
    fn update(&self, bytes: u64) {
        let processed = self.processed.fetch_add(bytes, Ordering::Relaxed);
        self.update_display(processed);
    }
}
```

## Error Handling

1. Error Types
```rust
#[derive(Error, Debug)]
pub enum ZipError {
    #[error("I/O error: {0}")]
    Io(#[from] std::io::Error),
    
    #[error("Invalid ZIP format: {0}")]
    Format(String),
    
    #[error("Unsupported compression method: {0}")]
    UnsupportedMethod(u16),
    
    #[error("Non-ASCII filename")]
    NonAsciiName,
    
    #[error("File too large (>4GB)")]
    FileTooLarge,
    
    #[error("Memory error: {0}")]
    Memory(String),
    
    #[error("No buffer available")]
    NoBufferAvailable,
    
    #[error("CRC32 mismatch")]
    Crc32Mismatch,
}
```

2. Recovery Strategy
```rust
impl ErrorHandler {
    fn handle(&self, error: &ZipError) -> Action {
        match error {
            ZipError::Io(_) => Action::SkipFile,
            ZipError::Memory(_) => Action::ReduceThreads,
            ZipError::Format(_) => Action::StopProcessing,
            _ => Action::LogAndContinue,
        }
    }
}
```

## Performance Optimizations

1. Cache Alignment
```rust
#[repr(align(64))]
struct AlignedBuffer {
    data: Vec<u8>,
    size: usize,
}
```

2. Batch Processing
```rust
impl Processor {
    fn process_batch(&self, entries: &[ZipEntry]) {
        if entries.len() < 10 {
            // Process directly
            self.process_sequential(entries);
        } else {
            // Process in parallel
            self.process_parallel(entries);
        }
    }
}
```

## Testing Strategy

1. Unit Tests
```rust
#[cfg(test)]
mod tests {
    #[test]
    fn test_zip_entry_validation() {
        let entry = ZipEntry {
            name: "test.txt".to_string(),
            size: 1024,
            method: 8,
            ..Default::default()
        };
        assert!(entry.validate().is_ok());
    }
}
```

2. Performance Tests
```rust
#[bench]
fn bench_parallel_processing(b: &mut Bencher) {
    b.iter(|| {
        let processor = Processor::new();
        processor.process_file("large_test.zip")
    });
}
```

3. Integration Tests
```rust
#[tokio::test]
async fn test_full_workflow() {
    let analyzer = Analyzer::new(Config::default());
    let result = analyzer.analyze("test.zip", "report.txt").await;
    assert!(result.is_ok());
}
```

4. Benchmarks
```rust
#[bench]
fn bench_parallel_processing(b: &mut Bencher) {
    b.iter(|| {
        let analyzer = Analyzer::new(Config::default());
        analyzer.analyze("large_test.zip", "report.txt")
    });
}
