# Parallel ZIP File Analyzer - PRD

## Section 1: Core Requirements 🎯

1. CLI tool to analyze a single ZIP file using parallel processing
2. Uses tokio for async I/O and rayon for parallel decompression
3. Outputs analysis to a text file
4. Shows progress bar during analysis
5. Handles large ZIP files (>10GB) efficiently via streaming
6. Provides detailed file statistics and compression info
7. Maintains memory efficiency through chunked processing
8. Graceful error handling
9. Simple CLI: `cargo run -- input.zip output.txt`

## Section 2: Architecture 🏗️

### Module Structure
```
src/
├── main.rs           // CLI + orchestration
├── models/
│   ├── mod.rs        // Re-exports
│   ├── file_info.rs  // Core file metadata
│   └── analysis.rs   // Analysis results + stats
├── analyzer/
│   ├── mod.rs        // Re-exports
│   ├── zip.rs        // Async ZIP processing
│   └── chunks.rs     // Parallel chunk handling
├── writer/
│   ├── mod.rs        // Re-exports
│   ├── report.rs     // Analysis output
│   └── progress.rs   // Progress tracking
└── error.rs          // Error handling
```

### Core Components

1. Async ZIP Engine
```rust
pub struct ParallelZipAnalyzer {
    zip_path: PathBuf,
    chunk_size: usize,
    thread_count: usize,
    buffer_pool: Arc<BufferPool>,
    memory_limit: usize,
    compression_dict: Option<Arc<CompressionDictionary>>,
    metrics_collector: Arc<MetricsCollector>,
}

pub struct BufferPool {
    buffers: ArrayQueue<Vec<u8>>,
    buffer_size: usize,
    total_size: AtomicUsize,
    pressure_threshold: f32,
    gc_trigger: AtomicBool,
}

pub struct CompressionDictionary {
    entries: HashMap<[u8; 32], CompressionPattern>,
    frequency: HashMap<CompressionPattern, usize>,
    optimization_threshold: f32,
}
```

2. Enhanced Chunk Processing
```rust
pub struct ChunkProcessor {
    chunk_size: usize,
    compression_level: u32,
    memory_limit: usize,
    thread_count: usize,
    adaptive_sizing: bool,
    chunk_overlap: usize,
    verification_level: VerificationLevel,
}

pub struct ChunkResult {
    offset: u64,
    files: Vec<FileInfo>,
    compressed_size: u64,
    uncompressed_size: u64,
    error: Option<AnalysisError>,
    metrics: ChunkMetrics,
    integrity_check: IntegrityInfo,
}

pub struct IntegrityInfo {
    crc32: u32,
    sha256: Option<[u8; 32]>,
    signature_valid: bool,
    structure_valid: bool,
}
```

3. Advanced Progress & Control
```rust
pub struct AnalyzerChannels {
    progress_tx: mpsc::Sender<ProgressUpdate>,
    chunk_results_tx: mpsc::Sender<ChunkResult>,
    control_rx: watch::Receiver<ControlSignal>,
    metrics_tx: mpsc::Sender<MetricsEvent>,
    debug_tx: mpsc::Sender<DebugInfo>,
}

pub enum ControlSignal {
    Continue,
    Pause,
    Stop { graceful: bool },
    MemoryPressure { target_reduction: usize },
    AdjustThreads { new_count: usize },
    UpdatePriority { priority: ProcessPriority },
}

#[derive(Debug)]
pub struct MetricsEvent {
    timestamp: SystemTime,
    event_type: MetricType,
    value: f64,
    context: HashMap<String, String>,
}
```

### Processing Pipeline with Optimizations
```
File I/O (tokio)          Processing (rayon)        Output
    ↓                           ↓                      ↓
Read Chunks       →     Parallel Analysis      →    Results
    ↓                           ↓                      ↓
Buffer Pool       →     Decompression         →    Progress
    ↓                           ↓                      ↓
Memory Monitor    →     Error Recovery        →    Reports
    ↓                           ↓                      ↓
Adaptive Sizing   →     Pattern Detection     →    Metrics
    ↓                           ↓                      ↓
I/O Prefetch      →     Dictionary Building   →    Analysis
```

### Enhanced Memory Management
```rust
pub struct MemoryConfig {
    chunk_size: usize,        // Default: 16MB
    max_total_mem: usize,     // Default: 80% available RAM
    buffer_pool_size: usize,  // Default: thread_count * 2
    pressure_threshold: f32,  // Default: 0.85
    gc_threshold: f32,        // Default: 0.95
    compression_cache: usize, // Default: 32MB
    adaptive_scaling: bool,   // Default: true
}

pub struct MemoryMetrics {
    current_usage: AtomicUsize,
    peak_usage: AtomicUsize,
    buffer_pool_size: AtomicUsize,
    pressure_events: AtomicUsize,
    gc_cycles: AtomicUsize,
    cache_hits: AtomicUsize,
    cache_misses: AtomicUsize,
}
```

### Sophisticated Error Recovery
```rust
pub enum RecoveryAction {
    Retry { 
        max_attempts: u32,
        backoff_strategy: BackoffStrategy,
    },
    SkipChunk { 
        log_error: bool,
        notify_user: bool,
    },
    ReduceMemory { 
        target_bytes: usize,
        aggressive: bool,
    },
    Abort { 
        cleanup: bool,
        dump_state: bool,
    },
    Fallback {
        alternative_method: ProcessingMethod,
        max_attempts: u32,
    },
}

pub struct RecoveryMetrics {
    retries: AtomicUsize,
    skipped_chunks: AtomicUsize,
    memory_reductions: AtomicUsize,
    successful_recoveries: AtomicUsize,
    fallback_attempts: AtomicUsize,
}

pub enum BackoffStrategy {
    Linear { base_ms: u64 },
    Exponential { base_ms: u64, max_ms: u64 },
    Fibonacci { max_steps: u32 },
}
```

### Performance Optimization Targets
- Throughput: >200MB/s on NVMe SSD
- Memory: <200MB baseline, scales with file size
- CPU: Adaptive thread scaling based on load
- Startup: <50ms to first progress update
- Cache Hit Rate: >85% for repeated patterns
- Recovery Success Rate: >95%

### Advanced Configuration
```rust
pub struct AnalyzerConfig {
    chunk_size: usize,
    thread_count: usize,
    memory_limit: usize,
    progress_interval: Duration,
    recovery_policy: RecoveryPolicy,
    buffer_pool_config: BufferPoolConfig,
    io_priority: IoPriority,
    compression_opts: CompressionOptions,
    metrics_config: MetricsConfig,
    debug_level: DebugLevel,
}

pub struct CompressionOptions {
    dictionary_enabled: bool,
    pattern_threshold: usize,
    optimization_level: OptLevel,
    cache_size: usize,
}

pub struct MetricsConfig {
    collection_interval: Duration,
    detailed_logging: bool,
    export_format: MetricsFormat,
    retention_policy: RetentionPolicy,
}
```

### Comprehensive Metrics Collection
```rust
pub struct AnalysisMetrics {
    duration: Duration,
    throughput: f64,
    compression_ratio: f64,
    memory_usage: MemoryMetrics,
    error_counts: HashMap<ErrorType, usize>,
    chunk_stats: ChunkMetrics,
    io_stats: IoMetrics,
    thread_stats: ThreadMetrics,
    pattern_stats: PatternMetrics,
}

pub struct IoMetrics {
    read_throughput: f64,
    write_throughput: f64,
    cache_stats: CacheStats,
    disk_queue_depth: usize,
    average_latency: Duration,
}

pub struct ThreadMetrics {
    active_threads: usize,
    thread_utilization: f64,
    context_switches: usize,
    work_stealing_events: usize,
}
```

### Enhanced Safety Considerations
- Buffer overflow protection
- Secure memory wiping
- Resource leak prevention
- Deadlock detection
- Panic recovery strategies
- Data corruption detection
- Thread sanitization
- Memory fence guarantees

### Future Extensions
- Multi-archive support
- Network streaming
- Content analysis
- Format detection
- Malware scanning
- Compression optimization
- Cloud integration
- Remote analysis
- Pattern learning
- Adaptive optimization

### Operational Considerations
- Logging strategy
- Metrics collection
- Performance monitoring
- Resource cleanup
- Error reporting
- Debug capabilities
- State persistence
- Recovery procedures

This design prioritizes:
1. Performance optimization
2. Resource efficiency
3. Reliability
4. Maintainability
5. Extensibility

### Terminal Setup Commands

```bash
# Navigate to project directory
cd /home/amuldotexe/Desktop/GitHub202410/iiwii01/exp004

# Create project structure in one command
mkdir -p src/{models,analyzer,writer} && \
touch src/main.rs \
      src/error.rs \
      src/models/{mod.rs,file_info.rs,analysis.rs} \
      src/analyzer/{mod.rs,zip.rs,chunks.rs} \
      src/writer/{mod.rs,report.rs,progress.rs}

# Verify structure
tree src/
```

Expected output:
```
src/
├── analyzer
│   ├── chunks.rs
│   ├── mod.rs
│   └── zip.rs
├── error.rs
├── main.rs
├── models
│   ├── analysis.rs
│   ├── file_info.rs
│   └── mod.rs
└── writer
    ├── mod.rs
    ├── progress.rs
    └── report.rs
```

### Detailed Module Specifications 📋

1. **Module Re-exports & Interfaces**
```rust
// models/mod.rs
pub use self::{
    file_info::FileInfo,
    analysis::{ZipAnalysis, PartialAnalysis, CompressionStats},
};

// analyzer/mod.rs
pub use self::{
    zip::ParallelZipAnalyzer,
    chunks::{ChunkConfig, ChunkProcessor, ChunkResult},
};

// writer/mod.rs
pub use self::{
    progress::{ProgressTracker, ProgressUpdate},
    report::ReportWriter,
};
```

2. **Thread Communication**
```rust
// analyzer/zip.rs
pub struct AnalyzerChannels {
    progress_tx: mpsc::Sender<ProgressUpdate>,
    chunk_results_tx: mpsc::Sender<ChunkResult>,
    control_tx: watch::Sender<ControlSignal>,
}

#[derive(Debug, Clone)]
pub enum ControlSignal {
    Continue,
    Pause,
    Stop { graceful: bool },
}

pub struct ChunkResult {
    offset: u64,
    files: Vec<FileInfo>,
    compressed_size: u64,
    uncompressed_size: u64,
    error: Option<AnalysisError>,
}
```

3. **Error Handling**
```rust
// error.rs
#[derive(Debug, thiserror::Error)]
pub enum AnalysisError {
    #[error("IO error at offset {offset}: {source}")]
    Io { 
        source: std::io::Error, 
        offset: u64 
    },
    
    #[error("ZIP error: {source}")]
    Zip { 
        source: zip::result::ZipError 
    },
    
    #[error("Corruption at {offset}, processed {processed_bytes} bytes")]
    Corrupt { 
        offset: u64, 
        processed_bytes: u64,
        partial_results: Option<PartialAnalysis>,
        recovery_possible: bool,
    },
    
    #[error("Memory limit exceeded: needed {required}MB, limit {max_allowed}MB")]
    Memory { 
        required: u64, 
        max_allowed: u64,
        current_usage: u64,
    },

    #[error("Progress reporting error: {msg}")]
    Progress { 
        msg: String 
    },

    #[error("Other error: {source}")]
    Other { 
        source: String 
    },
}

// Error Conversions
impl From<std::io::Error> for AnalysisError {
    fn from(error: std::io::Error) -> Self {
        AnalysisError::Io { 
            source: error,
            offset: 0
        }
    }
}

impl From<anyhow::Error> for AnalysisError {
    fn from(error: anyhow::Error) -> Self {
        AnalysisError::Other { 
            source: error.to_string() 
        }
    }
}
```

4. **Progress Tracking**
```rust
#[derive(Clone)]
pub struct ProgressTracker {
    bar: Arc<ProgressBar>,
    stats: Arc<RwLock<ProgressStats>>,
    config: ProgressConfig,
}

pub struct ProgressStats {
    bytes_processed: u64,
    files_processed: usize,
    current_file: String,
    compression_ratio: f64,
    estimated_remaining_secs: u64,
    error_count: usize,
}
```

5. **Compression Method Handling**
```rust
#[derive(Debug, Clone)]
pub enum CompressionMethod {
    Stored,
    Deflated,
    Other(u8),
}

impl From<zip::CompressionMethod> for CompressionMethod {
    fn from(method: zip::CompressionMethod) -> Self {
        match method {
            zip::CompressionMethod::Stored => Self::Stored,
            zip::CompressionMethod::Deflated => Self::Deflated,
            other => Self::Other(other.into())
        }
    }
}

impl std::fmt::Display for CompressionMethod {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Stored => write!(f, "Stored"),
            Self::Deflated => write!(f, "Deflated"),
            Self::Other(n) => write!(f, "Method({})", n)
        }
    }
}
```

6. **Results Merging Strategy**
```rust
// writer/report.rs
pub struct ReportWriter {
    output_path: PathBuf,
    format_config: FormatConfig,
}

pub struct FormatConfig {
    include_headers: bool,
    size_format: SizeFormat,
    sort_by: SortField,
    timestamp_format: String,
}

impl ReportWriter {
    pub fn new(path: PathBuf, config: FormatConfig) -> Self;
    pub async fn write(&self, analysis: &ZipAnalysis) -> Result<()>;
    pub async fn write_partial(&self, partial: &PartialAnalysis) -> Result<()>;
}
```

7. **Analysis Models**
```rust
// models/analysis.rs
pub struct ZipAnalysis {
    pub files: Vec<FileInfo>,
    pub total_size: u64,
    pub compressed_size: u64,
    pub compression_ratio: f64,
    pub stats: AnalysisStats,
}

pub struct AnalysisStats {
    pub duration_ms: u64,
    pub chunks_processed: usize,
    pub error_count: usize,
    pub peak_memory_mb: usize,
}

// models/file_info.rs
pub struct FileInfo {
    pub path: PathBuf,
    pub size: u64,
    pub compressed_size: u64,
    pub compression_method: CompressionMethod,
    pub crc32: u32,
    pub modified: DateTime<Utc>,
}
```


