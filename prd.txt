# Parallel ZIP File Analyzer - PRD

## Section 1: Core Requirements ğŸ¯

1. CLI tool to analyze a single ZIP file using parallel processing
2. Uses tokio for async I/O and rayon for parallel decompression
3. Outputs analysis to a text file
4. Shows progress bar during analysis
5. Handles large ZIP files (>10GB) efficiently via streaming
6. Provides detailed file statistics and compression info
7. Maintains memory efficiency through chunked processing
8. Graceful error handling
9. Simple CLI: `cargo run -- input.zip output.txt`

## Section 2: Architecture ğŸ—ï¸

### Module Structure
```
src/
â”œâ”€â”€ main.rs           // CLI + orchestration
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mod.rs        // Re-exports
â”‚   â”œâ”€â”€ file_info.rs  // Core file metadata
â”‚   â””â”€â”€ analysis.rs   // Analysis results + stats
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ mod.rs        // Re-exports
â”‚   â”œâ”€â”€ zip.rs        // Async ZIP processing
â”‚   â””â”€â”€ chunks.rs     // Parallel chunk handling
â”œâ”€â”€ writer/
â”‚   â”œâ”€â”€ mod.rs        // Re-exports
â”‚   â”œâ”€â”€ report.rs     // Analysis output
â”‚   â””â”€â”€ progress.rs   // Progress tracking
â””â”€â”€ error.rs          // Error handling
```

### Core Components

1. Async ZIP Engine
```rust
pub struct ParallelZipAnalyzer {
    zip_path: PathBuf,
    chunk_size: usize,
    thread_count: usize,
    buffer_pool: Arc<BufferPool>,
    memory_limit: usize,
}

pub struct BufferPool {
    buffers: ArrayQueue<Vec<u8>>,
    buffer_size: usize,
    total_size: AtomicUsize,
}
```

2. Chunk Processing
```rust
pub struct ChunkProcessor {
    chunk_size: usize,
    compression_level: u32,
    memory_limit: usize,
    thread_count: usize,
}

pub struct ChunkResult {
    offset: u64,
    files: Vec<FileInfo>,
    compressed_size: u64,
    uncompressed_size: u64,
    error: Option<AnalysisError>,
    metrics: ChunkMetrics,
}
```

3. Progress & Control
```rust
pub struct AnalyzerChannels {
    progress_tx: mpsc::Sender<ProgressUpdate>,
    chunk_results_tx: mpsc::Sender<ChunkResult>,
    control_rx: watch::Receiver<ControlSignal>,
}

pub enum ControlSignal {
    Continue,
    Pause,
    Stop { graceful: bool },
    MemoryPressure { target_reduction: usize },
}
```

### Processing Pipeline
```
File I/O (tokio)     Processing (rayon)     Output
    â†“                      â†“                   â†“
Read Chunks    â†’    Parallel Analysis   â†’   Results
    â†“                      â†“                   â†“
Buffer Pool    â†’    Decompression      â†’   Progress
    â†“                      â†“                   â†“
Memory Monitor â†’    Error Recovery     â†’   Reports
```

### Memory Management
```rust
pub struct MemoryConfig {
    chunk_size: usize,        // Default: 16MB
    max_total_mem: usize,     // Default: 80% available RAM
    buffer_pool_size: usize,  // Default: thread_count * 2
    pressure_threshold: f32,  // Default: 0.85
}

pub struct MemoryMetrics {
    current_usage: AtomicUsize,
    peak_usage: AtomicUsize,
    buffer_pool_size: AtomicUsize,
    pressure_events: AtomicUsize,
}
```

### Error Recovery Strategy
```rust
pub enum RecoveryAction {
    Retry { max_attempts: u32 },
    SkipChunk { log_error: bool },
    ReduceMemory { target_bytes: usize },
    Abort { cleanup: bool },
}

pub struct RecoveryMetrics {
    retries: AtomicUsize,
    skipped_chunks: AtomicUsize,
    memory_reductions: AtomicUsize,
}
```

### Performance Targets
- Throughput: >100MB/s on SSD
- Memory: <200MB baseline, scales with file size
- CPU: Efficient use of available cores
- Startup: <50ms to first progress update

### Configuration
```rust
pub struct AnalyzerConfig {
    chunk_size: usize,
    thread_count: usize,
    memory_limit: usize,
    progress_interval: Duration,
    recovery_policy: RecoveryPolicy,
    buffer_pool_config: BufferPoolConfig,
}
```

### Metrics Collection
```rust
pub struct AnalysisMetrics {
    duration: Duration,
    throughput: f64,
    compression_ratio: f64,
    memory_usage: MemoryMetrics,
    error_counts: HashMap<ErrorType, usize>,
    chunk_stats: ChunkMetrics,
}
```

### Safety Considerations
- Proper buffer management
- Graceful shutdown handling
- Memory pressure monitoring
- Error recovery policies
- Resource cleanup
- Panic handling in worker threads

### Future Extensions
- Multi-archive support
- Network streaming
- Content analysis
- Format detection
- Malware scanning
- Compression optimization

Remember:
- Tokio for async file I/O
- Rayon for parallel chunk processing
- Streaming for memory efficiency
- Clear progress feedback
- Simple CLI interface

This design balances:
1. Performance via chunk parallelism
2. Memory efficiency
3. User experience
4. Code maintainability

### Terminal Setup Commands

```bash
# Navigate to project directory
cd /home/amuldotexe/Desktop/GitHub202410/iiwii01/exp004

# Create project structure in one command
mkdir -p src/{models,analyzer,writer} && \
touch src/main.rs \
      src/error.rs \
      src/models/{mod.rs,file_info.rs,analysis.rs} \
      src/analyzer/{mod.rs,zip.rs,chunks.rs} \
      src/writer/{mod.rs,report.rs,progress.rs}

# Verify structure
tree src/
```

Expected output:
```
src/
â”œâ”€â”€ analyzer
â”‚   â”œâ”€â”€ chunks.rs
â”‚   â”œâ”€â”€ mod.rs
â”‚   â””â”€â”€ zip.rs
â”œâ”€â”€ error.rs
â”œâ”€â”€ main.rs
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ analysis.rs
â”‚   â”œâ”€â”€ file_info.rs
â”‚   â””â”€â”€ mod.rs
â””â”€â”€ writer
    â”œâ”€â”€ mod.rs
    â”œâ”€â”€ progress.rs
    â””â”€â”€ report.rs
```

### Detailed Module Specifications ğŸ“‹

1. **Module Re-exports & Interfaces**
```rust
// models/mod.rs
pub use self::{
    file_info::FileInfo,
    analysis::{ZipAnalysis, PartialAnalysis, CompressionStats},
};

// analyzer/mod.rs
pub use self::{
    zip::ParallelZipAnalyzer,
    chunks::{ChunkConfig, ChunkProcessor, ChunkResult},
};

// writer/mod.rs
pub use self::{
    progress::{ProgressTracker, ProgressUpdate},
    report::ReportWriter,
};
```

2. **Thread Communication**
```rust
// analyzer/zip.rs
pub struct AnalyzerChannels {
    progress_tx: mpsc::Sender<ProgressUpdate>,
    chunk_results_tx: mpsc::Sender<ChunkResult>,
    control_tx: watch::Sender<ControlSignal>,
}

#[derive(Debug, Clone)]
pub enum ControlSignal {
    Continue,
    Pause,
    Stop { graceful: bool },
}

pub struct ChunkResult {
    offset: u64,
    files: Vec<FileInfo>,
    compressed_size: u64,
    uncompressed_size: u64,
    error: Option<AnalysisError>,
}
```

3. **Error Handling**
```rust
// error.rs
#[derive(Debug, thiserror::Error)]
pub enum AnalysisError {
    #[error("IO error at offset {offset}: {source}")]
    Io { 
        source: std::io::Error, 
        offset: u64 
    },
    
    #[error("ZIP error: {source}")]
    Zip { 
        source: zip::result::ZipError 
    },
    
    #[error("Corruption at {offset}, processed {processed_bytes} bytes")]
    Corrupt { 
        offset: u64, 
        processed_bytes: u64,
        partial_results: Option<PartialAnalysis>,
        recovery_possible: bool,
    },
    
    #[error("Memory limit exceeded: needed {required}MB, limit {max_allowed}MB")]
    Memory { 
        required: u64, 
        max_allowed: u64,
        current_usage: u64,
    },

    #[error("Progress reporting error: {msg}")]
    Progress { 
        msg: String 
    },

    #[error("Other error: {source}")]
    Other { 
        source: String 
    },
}

// Error Conversions
impl From<std::io::Error> for AnalysisError {
    fn from(error: std::io::Error) -> Self {
        AnalysisError::Io { 
            source: error,
            offset: 0
        }
    }
}

impl From<anyhow::Error> for AnalysisError {
    fn from(error: anyhow::Error) -> Self {
        AnalysisError::Other { 
            source: error.to_string() 
        }
    }
}
```

4. **Progress Tracking**
```rust
#[derive(Clone)]
pub struct ProgressTracker {
    bar: Arc<ProgressBar>,
    stats: Arc<RwLock<ProgressStats>>,
    config: ProgressConfig,
}

pub struct ProgressStats {
    bytes_processed: u64,
    files_processed: usize,
    current_file: String,
    compression_ratio: f64,
    estimated_remaining_secs: u64,
    error_count: usize,
}
```

5. **Compression Method Handling**
```rust
#[derive(Debug, Clone)]
pub enum CompressionMethod {
    Stored,
    Deflated,
    Other(u8),
}

impl From<zip::CompressionMethod> for CompressionMethod {
    fn from(method: zip::CompressionMethod) -> Self {
        match method {
            zip::CompressionMethod::Stored => Self::Stored,
            zip::CompressionMethod::Deflated => Self::Deflated,
            other => Self::Other(other.into())
        }
    }
}

impl std::fmt::Display for CompressionMethod {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Stored => write!(f, "Stored"),
            Self::Deflated => write!(f, "Deflated"),
            Self::Other(n) => write!(f, "Method({})", n)
        }
    }
}
```

6. **Results Merging Strategy**
```rust
// writer/report.rs
pub struct ReportWriter {
    output_path: PathBuf,
    format_config: FormatConfig,
}

pub struct FormatConfig {
    include_headers: bool,
    size_format: SizeFormat,
    sort_by: SortField,
    timestamp_format: String,
}

impl ReportWriter {
    pub fn new(path: PathBuf, config: FormatConfig) -> Self;
    pub async fn write(&self, analysis: &ZipAnalysis) -> Result<()>;
    pub async fn write_partial(&self, partial: &PartialAnalysis) -> Result<()>;
}
```

7. **Analysis Models**
```rust
// models/analysis.rs
pub struct ZipAnalysis {
    pub files: Vec<FileInfo>,
    pub total_size: u64,
    pub compressed_size: u64,
    pub compression_ratio: f64,
    pub stats: AnalysisStats,
}

pub struct AnalysisStats {
    pub duration_ms: u64,
    pub chunks_processed: usize,
    pub error_count: usize,
    pub peak_memory_mb: usize,
}

// models/file_info.rs
pub struct FileInfo {
    pub path: PathBuf,
    pub size: u64,
    pub compressed_size: u64,
    pub compression_method: CompressionMethod,
    pub crc32: u32,
    pub modified: DateTime<Utc>,
}
```


