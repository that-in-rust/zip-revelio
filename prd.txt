# Parallel ZIP File Analyzer - PRD

## Section 1: Core Requirements ğŸ¯

1. CLI tool to analyze a single ZIP file using parallel processing
2. Uses tokio for async I/O and rayon for parallel decompression
3. Outputs analysis to a text file
4. Shows progress bar during analysis
5. Handles large ZIP files (>10GB) efficiently via streaming
6. Provides detailed file statistics and compression info
7. Maintains memory efficiency through chunked processing
8. Graceful error handling
9. Simple CLI: `cargo run -- input.zip output.txt`

## Section 2: Architecture ğŸ—ï¸

### Module Structure
```
src/
â”œâ”€â”€ main.rs           // CLI + orchestration
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mod.rs        // Re-exports
â”‚   â”œâ”€â”€ file_info.rs  // Core file metadata
â”‚   â””â”€â”€ analysis.rs   // Analysis results + stats
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ mod.rs        // Re-exports
â”‚   â”œâ”€â”€ zip.rs        // Async ZIP processing
â”‚   â””â”€â”€ chunks.rs     // Parallel chunk handling
â”œâ”€â”€ writer/
â”‚   â”œâ”€â”€ mod.rs        // Re-exports
â”‚   â”œâ”€â”€ report.rs     // Analysis output
â”‚   â””â”€â”€ progress.rs   // Progress tracking
â””â”€â”€ error.rs          // Error handling
```

### Core Components

1. Async ZIP Engine
```rust
pub struct ParallelZipAnalyzer {
    zip_path: PathBuf,
    chunk_size: usize,
    thread_count: usize,
    buffer_pool: Arc<BufferPool>,
    memory_limit: usize,
    compression_dict: Option<Arc<CompressionDictionary>>,
    metrics_collector: Arc<MetricsCollector>,
}

pub struct BufferPool {
    buffers: ArrayQueue<Vec<u8>>,
    buffer_size: usize,
    total_size: AtomicUsize,
    pressure_threshold: f32,
    gc_trigger: AtomicBool,
}

pub struct CompressionDictionary {
    entries: HashMap<[u8; 32], CompressionPattern>,
    frequency: HashMap<CompressionPattern, usize>,
    optimization_threshold: f32,
}
```

2. Enhanced Chunk Processing
```rust
pub struct ChunkProcessor {
    chunk_size: usize,
    compression_level: u32,
    memory_limit: usize,
    thread_count: usize,
    adaptive_sizing: bool,
    chunk_overlap: usize,
    verification_level: VerificationLevel,
}

pub struct ChunkResult {
    offset: u64,
    files: Vec<FileInfo>,
    compressed_size: u64,
    uncompressed_size: u64,
    error: Option<AnalysisError>,
    metrics: ChunkMetrics,
    integrity_check: IntegrityInfo,
}

pub struct IntegrityInfo {
    crc32: u32,
    sha256: Option<[u8; 32]>,
    signature_valid: bool,
    structure_valid: bool,
}
```

3. Advanced Progress & Control
```rust
pub struct AnalyzerChannels {
    progress_tx: mpsc::Sender<ProgressUpdate>,
    chunk_results_tx: mpsc::Sender<ChunkResult>,
    control_rx: watch::Receiver<ControlSignal>,
    metrics_tx: mpsc::Sender<MetricsEvent>,
    debug_tx: mpsc::Sender<DebugInfo>,
}

pub enum ControlSignal {
    Continue,
    Pause,
    Stop { graceful: bool },
    MemoryPressure { target_reduction: usize },
    AdjustThreads { new_count: usize },
    UpdatePriority { priority: ProcessPriority },
}

#[derive(Debug)]
pub struct MetricsEvent {
    timestamp: SystemTime,
    event_type: MetricType,
    value: f64,
    context: HashMap<String, String>,
}
```

### Processing Pipeline with Optimizations
```
File I/O (tokio)          Processing (rayon)        Output
    â†“                           â†“                      â†“
Read Chunks       â†’     Parallel Analysis      â†’    Results
    â†“                           â†“                      â†“
Buffer Pool       â†’     Decompression         â†’    Progress
    â†“                           â†“                      â†“
Memory Monitor    â†’     Error Recovery        â†’    Reports
    â†“                           â†“                      â†“
Adaptive Sizing   â†’     Pattern Detection     â†’    Metrics
    â†“                           â†“                      â†“
I/O Prefetch      â†’     Dictionary Building   â†’    Analysis
```

### Enhanced Memory Management
```rust
pub struct MemoryConfig {
    chunk_size: usize,        // Default: 16MB
    max_total_mem: usize,     // Default: 80% available RAM
    buffer_pool_size: usize,  // Default: thread_count * 2
    pressure_threshold: f32,  // Default: 0.85
    gc_threshold: f32,        // Default: 0.95
    compression_cache: usize, // Default: 32MB
    adaptive_scaling: bool,   // Default: true
}

pub struct MemoryMetrics {
    current_usage: AtomicUsize,
    peak_usage: AtomicUsize,
    buffer_pool_size: AtomicUsize,
    pressure_events: AtomicUsize,
    gc_cycles: AtomicUsize,
    cache_hits: AtomicUsize,
    cache_misses: AtomicUsize,
}
```

### Sophisticated Error Recovery
```rust
pub enum RecoveryAction {
    Retry { 
        max_attempts: u32,
        backoff_strategy: BackoffStrategy,
    },
    SkipChunk { 
        log_error: bool,
        notify_user: bool,
    },
    ReduceMemory { 
        target_bytes: usize,
        aggressive: bool,
    },
    Abort { 
        cleanup: bool,
        dump_state: bool,
    },
    Fallback {
        alternative_method: ProcessingMethod,
        max_attempts: u32,
    },
}

pub struct RecoveryMetrics {
    retries: AtomicUsize,
    skipped_chunks: AtomicUsize,
    memory_reductions: AtomicUsize,
    successful_recoveries: AtomicUsize,
    fallback_attempts: AtomicUsize,
}

pub enum BackoffStrategy {
    Linear { base_ms: u64 },
    Exponential { base_ms: u64, max_ms: u64 },
    Fibonacci { max_steps: u32 },
}
```

### Performance Optimization Targets
- Throughput: >200MB/s on NVMe SSD
- Memory: <200MB baseline, scales with file size
- CPU: Adaptive thread scaling based on load
- Startup: <50ms to first progress update
- Cache Hit Rate: >85% for repeated patterns
- Recovery Success Rate: >95%

### Advanced Configuration
```rust
pub struct AnalyzerConfig {
    chunk_size: usize,
    thread_count: usize,
    memory_limit: usize,
    progress_interval: Duration,
    recovery_policy: RecoveryPolicy,
    buffer_pool_config: BufferPoolConfig,
    io_priority: IoPriority,
    compression_opts: CompressionOptions,
    metrics_config: MetricsConfig,
    debug_level: DebugLevel,
}

pub struct CompressionOptions {
    dictionary_enabled: bool,
    pattern_threshold: usize,
    optimization_level: OptLevel,
    cache_size: usize,
}

pub struct MetricsConfig {
    collection_interval: Duration,
    detailed_logging: bool,
    export_format: MetricsFormat,
    retention_policy: RetentionPolicy,
}
```

### Comprehensive Metrics Collection
```rust
pub struct AnalysisMetrics {
    duration: Duration,
    throughput: f64,
    compression_ratio: f64,
    memory_usage: MemoryMetrics,
    error_counts: HashMap<ErrorType, usize>,
    chunk_stats: ChunkMetrics,
    io_stats: IoMetrics,
    thread_stats: ThreadMetrics,
    pattern_stats: PatternMetrics,
}

pub struct IoMetrics {
    read_throughput: f64,
    write_throughput: f64,
    cache_stats: CacheStats,
    disk_queue_depth: usize,
    average_latency: Duration,
}

pub struct ThreadMetrics {
    active_threads: usize,
    thread_utilization: f64,
    context_switches: usize,
    work_stealing_events: usize,
}
```

### Enhanced Safety Considerations
- Buffer overflow protection
- Secure memory wiping
- Resource leak prevention
- Deadlock detection
- Panic recovery strategies
- Data corruption detection
- Thread sanitization
- Memory fence guarantees

### Future Extensions
- Multi-archive support
- Network streaming
- Content analysis
- Format detection
- Malware scanning
- Compression optimization
- Cloud integration
- Remote analysis
- Pattern learning
- Adaptive optimization

### Operational Considerations
- Logging strategy
- Metrics collection
- Performance monitoring
- Resource cleanup
- Error reporting
- Debug capabilities
- State persistence
- Recovery procedures

This design prioritizes:
1. Performance optimization
2. Resource efficiency
3. Reliability
4. Maintainability
5. Extensibility

### Terminal Setup Commands

```bash
# Navigate to project directory
cd /home/amuldotexe/Desktop/GitHub202410/iiwii01/exp004

# Create project structure in one command
mkdir -p src/{models,analyzer,writer} && \
touch src/main.rs \
      src/error.rs \
      src/models/{mod.rs,file_info.rs,analysis.rs} \
      src/analyzer/{mod.rs,zip.rs,chunks.rs} \
      src/writer/{mod.rs,report.rs,progress.rs}

# Verify structure
tree src/
```

Expected output:
```
src/
â”œâ”€â”€ analyzer
â”‚   â”œâ”€â”€ chunks.rs
â”‚   â”œâ”€â”€ mod.rs
â”‚   â””â”€â”€ zip.rs
â”œâ”€â”€ error.rs
â”œâ”€â”€ main.rs
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ analysis.rs
â”‚   â”œâ”€â”€ file_info.rs
â”‚   â””â”€â”€ mod.rs
â””â”€â”€ writer
    â”œâ”€â”€ mod.rs
    â”œâ”€â”€ progress.rs
    â””â”€â”€ report.rs
```

### Detailed Module Specifications ğŸ“‹

1. **Module Re-exports & Interfaces**
```rust
// models/mod.rs
pub use self::{
    file_info::FileInfo,
    analysis::{ZipAnalysis, PartialAnalysis, CompressionStats},
};

// analyzer/mod.rs
pub use self::{
    zip::ParallelZipAnalyzer,
    chunks::{ChunkConfig, ChunkProcessor, ChunkResult},
};

// writer/mod.rs
pub use self::{
    progress::{ProgressTracker, ProgressUpdate},
    report::ReportWriter,
};
```

2. **Thread Communication**
```rust
// analyzer/zip.rs
pub struct AnalyzerChannels {
    progress_tx: mpsc::Sender<ProgressUpdate>,
    chunk_results_tx: mpsc::Sender<ChunkResult>,
    control_tx: watch::Sender<ControlSignal>,
}

#[derive(Debug, Clone)]
pub enum ControlSignal {
    Continue,
    Pause,
    Stop { graceful: bool },
}

pub struct ChunkResult {
    offset: u64,
    files: Vec<FileInfo>,
    compressed_size: u64,
    uncompressed_size: u64,
    error: Option<AnalysisError>,
}
```

3. **Error Handling**
```rust
// error.rs
#[derive(Debug, thiserror::Error)]
pub enum AnalysisError {
    #[error("IO error at offset {offset}: {source}")]
    Io { 
        source: std::io::Error, 
        offset: u64 
    },
    
    #[error("ZIP error: {source}")]
    Zip { 
        source: zip::result::ZipError 
    },
    
    #[error("Corruption at {offset}, processed {processed_bytes} bytes")]
    Corrupt { 
        offset: u64, 
        processed_bytes: u64,
        partial_results: Option<PartialAnalysis>,
        recovery_possible: bool,
    },
    
    #[error("Memory limit exceeded: needed {required}MB, limit {max_allowed}MB")]
    Memory { 
        required: u64, 
        max_allowed: u64,
        current_usage: u64,
    },

    #[error("Progress reporting error: {msg}")]
    Progress { 
        msg: String 
    },

    #[error("Other error: {source}")]
    Other { 
        source: String 
    },
}

// Error Conversions
impl From<std::io::Error> for AnalysisError {
    fn from(error: std::io::Error) -> Self {
        AnalysisError::Io { 
            source: error,
            offset: 0
        }
    }
}

impl From<anyhow::Error> for AnalysisError {
    fn from(error: anyhow::Error) -> Self {
        AnalysisError::Other { 
            source: error.to_string() 
        }
    }
}
```

4. **Progress Tracking**
```rust
#[derive(Clone)]
pub struct ProgressTracker {
    bar: Arc<ProgressBar>,
    stats: Arc<RwLock<ProgressStats>>,
    config: ProgressConfig,
}

pub struct ProgressStats {
    bytes_processed: u64,
    files_processed: usize,
    current_file: String,
    compression_ratio: f64,
    estimated_remaining_secs: u64,
    error_count: usize,
}
```

5. **Compression Method Handling**
```rust
#[derive(Debug, Clone)]
pub enum CompressionMethod {
    Stored,
    Deflated,
    Other(u8),
}

impl From<zip::CompressionMethod> for CompressionMethod {
    fn from(method: zip::CompressionMethod) -> Self {
        match method {
            zip::CompressionMethod::Stored => Self::Stored,
            zip::CompressionMethod::Deflated => Self::Deflated,
            other => Self::Other(other.into())
        }
    }
}

impl std::fmt::Display for CompressionMethod {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Stored => write!(f, "Stored"),
            Self::Deflated => write!(f, "Deflated"),
            Self::Other(n) => write!(f, "Method({})", n)
        }
    }
}
```

6. **Results Merging Strategy**
```rust
// writer/report.rs
pub struct ReportWriter {
    output_path: PathBuf,
    format_config: FormatConfig,
}

pub struct FormatConfig {
    include_headers: bool,
    size_format: SizeFormat,
    sort_by: SortField,
    timestamp_format: String,
}

impl ReportWriter {
    pub fn new(path: PathBuf, config: FormatConfig) -> Self;
    pub async fn write(&self, analysis: &ZipAnalysis) -> Result<()>;
    pub async fn write_partial(&self, partial: &PartialAnalysis) -> Result<()>;
}
```

7. **Analysis Models**
```rust
// models/analysis.rs
pub struct ZipAnalysis {
    pub files: Vec<FileInfo>,
    pub total_size: u64,
    pub compressed_size: u64,
    pub compression_ratio: f64,
    pub stats: AnalysisStats,
}

pub struct AnalysisStats {
    pub duration_ms: u64,
    pub chunks_processed: usize,
    pub error_count: usize,
    pub peak_memory_mb: usize,
}

// models/file_info.rs
pub struct FileInfo {
    pub path: PathBuf,
    pub size: u64,
    pub compressed_size: u64,
    pub compression_method: CompressionMethod,
    pub crc32: u32,
    pub modified: DateTime<Utc>,
}
```


